В этой части курса мы познакомимся с алгоритмами на графах и отчасти с 
сортировками данных. Существует множество алгоритмов на графах, мы 
остановим своё внимание на самых базовых --- поиске в глубину 
(Depth-first search, $DFS$) и поиске в ширину (Breadth-first search
, $BFS$). Данные алгоритмы являются основой множества других более 
сложных алгоритмов (алгоритм Дейкстры, алгоритм топологической 
сортировки), о которых вы сможете прочитать в литературе, посвященной
алгоритмам.

\section{Анализ алгоритмов}
\subsection{Базовые определения}
Стоит начать с неформального определения алгоритма, так как,
во-первых, этого достаточно для нашего курса, а во-вторых, не существует
единого формального определения.

\begin{mydef}
    Алгоритм --- это любая корректно определённая процедура на
    вход ($input$) которой подаётся некоторая величина или набор таких
    величин, и результатом работы которой является некоторая выходная
    ($output$) величина или набора таких величин.
\end{mydef}

Кроме того, прежде чем начать изучение самих алгоритмов, стоит сказать о 
важной части анализа алгоритмов --- их временных характеристиках. Это,
во-превых, время работы в среднем, а во-вторых, время работы в худшем
случае. В рамках нашей занятий будем рассматривать только последнюю 
характеристику.

Вообще говоря, точный подсчёт времени работы алгоритма крайне труден,
так как необходимо знать <<стоимость>> (время выполнения) каждой
элементарной операции. Рапостранённым подходом является оценка порядка
количества операций от входа, то есть мы игнорируем стоимость
элементарных операций, оценивая их число по отношению к размеру входа.
При таком подходе различие времени работы в 2 или 1000 раз не
существенно по сравнению с разницей в $n$ раз ($n$ --- длинна входа).

Введём некоторые определения, с помощью которых мы будем проводить 
классификацию функций по времени работы. 

\begin{mydef}
	Пусть даны две функции $f(n)$ и $g(n)$ натурального аргумента $n$,
    значениями которых являются положительные действительные числа.
    Говорят, что $f = O(g)$ (<<$f$ растёт не быстрее $g$>>), если
    существует такая константа $c > 0$ и такое натуральное $N$, что
    $f(n) \leqslant c \ g(n)$ для всех $n > \N$.
\end{mydef}

\begin{mydef}
	Пусть даны две функции $f(n)$ и $g(n)$ натурального аргумента $n$,
    значениями которых являются положительные действительные числа.
    Говорят, что $f = \Theta(g)$ (<<$f$ и $g$ имеют одинаковую скорость
    роста>>), если существуют такие константы $c_1,\ c_2 > 0$ и такое
    натуральное $N$, что $c_1 f(n) \leqslant g(n) \leqslant c_2
    f(n)$ для всех $n > N$.
\end{mydef}

Неформально говоря, $f = O(g)$ означает $f \leqslant g$ в некотором смысле.
Аналогично $f = \Theta(g)$ значит, что $f \approx g$ при больших $n$. Как 
можно догадаться, существуют и другие похожие определения, но они нам не 
понадобятся. 

\begin{example}
    Рассмотрим функции $f(n) = n^2$ и $g(n) = 3n^2 + 2n + 1$. Несложно
    заметить, что при больших $n$ младшие степени функции $g$ малы
    по сравнению с квадратичным слагаемым. Поэтому $f(n) = \Theta(g(n))$.
    Попробуйте самостоятельно подобрать константы из определения.
    Аналогичными (но более общими) рассуждениями можно показать, что
    многочлены одной степени имеют одинаковую скорость роста.
\end{example}

\begin{example}
    Возьмем $f(n) = n^2$ и $g(n) = 2^n$. Несложно по индукции доказать,
    что $f(n) \leqslant g(n)$ при $n > 3$. Значит, $f(n) = O(g(n))$.
    Однако обратное неверно. Увидеть это можно, начав выписывать
    первые значения обеих функций. На самом деле экспоненциальная
    функция с любым (большим единицы) основанием растет намного быстрее,
    чем полином. Поэтому ученые так много усилий тратят на то, чтобы
    в некоторой задаче с известным экспоненциальным алгоритмом
    найти алгоритм, работающий за полиномиальное время.
\end{example}

Теперь рассмотрим простой пример, который покажет применение формальных
определений на практике. Мы описывать алгоритмы неформально. Начальные 
данные --- есть стопка из $N$ пластинок, на каждой из которых написано 
некоторое число, а также ручка и тетрадь. В первой задаче необходимо 
просто посчитать сумму всех чисел.

\begin{enumerate}
    {\tt
    \item Возьмём новый лист и запишем на него 0. Назовем 
        это число суммой
    \item Возьмём из стопки верхнюю табличку
    \item Прибавим число с неё к сумме (сумма обновится)
    \item Отложим просмотренну табличку в другую стопку
    \item Пока в исходной стопке есть карточки, повторяем шаги 2-4
    }
\end{enumerate}

В качестве ответа возьмем то число, которое мы называем суммой. Легко 
проверить, что наш алгоритм корректно решает поставленную задачу. Кроме того,
очевидно, что если считать суммирование и перемещение карточек элементарными 
операциями со стоимостью 1, то мы получили алгоритм, который совершает $3n$
операций. Таким образом, сложность нашего алгоритма --- $O(N)$. При этом 
сложность не изменится, даже если мы не будем знать, сколько времени занимает
каждая операция, но будем считать, что их стоимость не зависит от величины 
входа. То есть какими бы большими ни были числа на табличках, мы полагаем,
что сложение их происходит быстро (одна элементарная операция).

\subsection{Сортировки}

Теперь давайте отсортируем карточки по возрастанию чисел на них. Для этого 
воспользуемся следующим алгоритмом.

\begin{enumerate}
    {\tt
    \item Возьмём из стопки верхнюю табличку. Назовем ее минимумом и 
        отложим
    \item Возьмём из стопки верхнюю табличку, сравним число на ней с 
        минимумом. \\ Отложим её в сторону, если число на ней
        не меньше минимума. В ином \\ случае отложим старый минимум в 
        сторону, а в качестве нового возьмем \\ выбранную карточку
    \item Пока в исходной стопке есть карточки, повторяем шаг 2
    \item Соберём отложенные карточки в стопку. Минимум положим сверху 
        в \\ другую специальную стопку
    \item Пока в исходной стопке есть карточки, повторяем шаги 2-4
    }
\end{enumerate}

Легко убедиться, что алгоритм корректен, так как мы выбираем минимум из всех
карточек, откладываем его в сторону, затем ищем минимум среди оставшихся карточек.
Продолжаем мы этот процесс, пока все карточки не будут лежать в стопке ответа.
Кроме того, из построения очевидно, что в ответной стопке под любой карточкой 
содержатся только меньшие её карточки. Приведённый выше алгоритм --- это аналог
сортировки выбором (insertion sort) минимума, применённый к нашей задаче.

Сложность данной сортировки равна $O(N^2)$, что очень легко наблюдать. 
Всего необходимо выполнить $N$ переборов исходной стопки. При этом первый раз 
мы сделаем $N-1$ сравнение, второй раз $N-2$ и так делее. В сумме получим
$N(N-1)/2$. Теперь еще раз обозначим тонкий момент: опуская коэффициенты, мы 
также опускаем и младшие степени полиномов, поскольку ясно, что линейная 
функция растёт медленнее квадратичной, то есть для фиксированного $c > 0$ при
больших $N$ выполнено $N(N-1)/2 > cN$. Это важно и из этого мы получаем, что
сложность нашей сортировки --- $O(N^2)$.

Опишем пример ещё одной сортировки --- пузырьком (bubble sort), сложность которой
также равна $O(N^2)$. Сортировка пузырьком --- очень простой, базовый алгоритм,
который на практике используется мало, во всяком случае в его чистом виде.
Однако, некоторое его принципы использует широко распостранённая быстрая сортировка.

Рассмотрим сортировку пузырьком также в применении к нашей модели с табличками.
Будем считать, что в этот раз таблички выложены в ряд и мы должны отсортировать их 
слева направо по возрастанию чисел. Кроме того, таблички лежат на пронумированных 
местах так, что самая левая лежит на первом месте, справо от неё вторая и так далее.

\begin{enumerate}
    {\tt
    \item Пусть текущая карточка - это первая.
    \item Сравним её значение с карточкой справа от неё. Если текущая карточка \\ 
        имеет большее значение, меняем её и карточку справа от неё местами, \\ иначе 
        оставляем всё как есть и текущей карточкой считаем карточку \\ справа
    \item Повторяем шаги 1-2, пока текущей не станет самая правая карточка
    \item Повторяем шаги 1-3 N-2 раза
    }
\end{enumerate}

\smallskip

Действие данной сортировки похоже на сортировку выбором. Заметим, что на первом 
этапе исполнения шагов $1-3$ мы отыщем самое большое число и переместим его в правый
конец ряда. Затем будет следующее по величине число и так далее. Таким образом, мы за
$N-1$ проход по ряду выставим $N-1$ число справа налево по убыванию, а последнее 
число может быть только самым маленьким среди всех. В итоге мы получаем отсортированный
по требованию задачи ряд.

Сразу же можно заметить, что сортировка выполняет лишние действия, то есть действия,
которые в силу построения гарантированно не вызовут изменений в последовательности
чисел. Например, очевидно, что перед каждым из $N-1$ этапов прохода по ряду стоит
определять, были ли совершены какие-то изменения в прошлом проходе. Если их не было,
то и текущий проход ничего не изменит. Кроме того, совсем не обязательно проходить 
каждый раз весь ряд, так как на $i$-ом проходе мы будем иметь уже отсортированные
последние $i$ чисел.

Теперь скажем пару слов о сложности алгоритма. Во-первых, заметим, что мы совершаем 
$N-1$ проход и $N-1$ сравнение. Таким образом, пренебрегая остальными операциями 
(перекладывание карточек можно считать частью сравнения, перемещение мгновенное),
мы получаем $N^2 - 2N + 1$ операций, то есть сложность алгоритма равна $O(N^2)$.

Рассмотрим теперь сортировку, которая работает за время $O(N \log N)$\footnote{
Мы не пишем основание логарифма, поскольку разные логарифмы пропорциональны, то
есть равны в наших обозначениях}. Называется она сортировкой слиянием (merge sort),
смысл названия станет понятен после знакомства с алгоритмом.

Итак, у нас есть та же последовательность карточек. Мы хотим отсортировать ее по
возрастанию. Воспользуемся методом, который известен под названием <<разделяй и
властвуй>> (divide and conquer). Смысл его прост: мы разбиваем задачу на подзадачи,
решаем подзадачи и объединяем их решения в решение исходной задачи. Общий алгоритм
выглядит так:

\begin{enumerate}
    {\tt
    \item Разбиваем ряд из карточек на две равные части
    \item Для левой части вызываем алгоритм сортировки, если ее длина больше 2 \\
        Если длина равна 2, отсортируем с помощью одного сравнения
    \item Для правой части вызываем алгоритм сортировки, если ее длина больше 2 \\
        Если длина равна 2, отсортируем также с помощью сравнения
    \item Вызываем алгоритм слияния двух отсортированных последовательностей
    }
\end{enumerate}

Здесь мы используем вспомогательный алгоритм слияния. Устроен он достаточно просто:
Мы проходимся по карточкам обеих последовательностей и в итоговый массив кладем
меньшую карточку. Итак, у нас имеется два отсортированных ряда. Мы делаем следующее

\begin{enumerate}
    {\tt
    \item Берем самую левую карточку из первого ряда. Назовем ее карточкой А \\
        Берем самую левую карточку из второго ряда. Назовем ее карточкой Б
    \item Из карточек А и Б выбираем ту, на которой написано меньшее число. \\
        Кладем ее в ряд для общего массива справа. Берем следующую карточку \\
        справа для А или Б соответственно.
    \item Повторяем шаг 2, пока один из рядов не закончится
    \item Переносим оставшиеся карточки по одной в общий массив, добавляя их \\
        справа в том же порядке
    }
\end{enumerate}

Корректность алгоритма можно показать с помощью индукции. Когда мы получим части
длины 1 или 2, они будут уже отсортированны либо изначально, либо после одной
операции. Когда мы делаем операцию слияния, то мы добавляем в большой ряд
элементы из половинок, причем только их. Кроме того, добавляем мы их в нужном
порядке. Значит, и больший ряд будет отсортирован.

Попробуем теперь оценить сложность данного алгоритма. Сделать это уже не так
просто. Попробуем выписать некоторое равенство. Пусть $T(n)$ --- число
операций для сортировки слиянием ряда из $n$ карточек. Тогда несложно
заметить, что
\[
    T(n) = 2T(n/2) + \Theta(n).
    \]

Первое слагаемое отвечает за решение двух подзадач --- сортировок рядов длины
$n/2$, а второе --- за слияние результатов (при этом можно взять такое $c > 0$,
что слияние частей при любом $n$ не превосходит $cn$). Нам нужно посчитать число 
всех операций слияния, это и будет временем работы. Обозначим уровнем глубины $i$
все подпоследовательности после $i$ разбиений исходного ряда (тогда исходный
ряд --- это уровень глубины 0). Заметим, что на $i$-м уровне присутствуют
$2^i$ последовательностей, каждая длины примерно $n/2^i$. Значит, на каждом
уровне выполняется слияний не более, чем 
\[
    2^i\ \frac{n}{2^i}\ c = nc.
    \]

А уровней будет в точности двоичный логарифм $n$ (если точнее --- целая часть).
Отсюда получаем, что время работы не превосходит $cn \log n$, то есть равно
$O(n \log n)$.

Есть множество других интересных и довольно простых сортировок. Например, 
сортировка кучей (heap sort) или быстрая сортировка (quick sort). Однако,
для понимания принципов анализа алгоритмов разобранных примеров нам хватит.

\subsection{Структуры данных}

Для работы с алгоритмами нам понадобятся некоторые структуры данных. Самые
простые --- массив и список (мы рассмотрим двусвязный список). Для того, 
чтобы понимать их суть, нужно упомянуть о том, как устроена память в
компьютере. Будем считать память бесконечной лентой, в каждую ячейку которой
можно записать число\footnote{конечно, лента не бесконечна, но она достаточно большая,
поэтому в наших задачах это разумное допущение}. При этом разные ячейки
могут быть как свободны, так и заняты различными программами --- никакого
строгого порядка тут нет. У каждой ячейки есть номер, по этому номеру можно
получать содержимое (то, что нам и нужно --- данные).

\begin{itemize}
    \item Массив --- этот тот самый ряд из карточек, то есть последовательность
        однотипных элементов (будем считать, что чисел). Когда компьютер 
        получает запрос <<выделить пользователю массив длины $n$>>, он находит 
        $n$ подряд идущих свободных ячеек и отдает их пользователю.
    \item Список. Представим, что на карточке написано не только число, но 
        и номера ячеек памяти, где расположены следующая и предыдущая карточки. 
        Заметим, что в таком случае карточки выстраиваются в цепочку, по которой
        можно перемещаться с помощью указателей --- записанных адресов ячеек. 
        Для того, чтобы получить список, необходимо по одному добавлять в него 
        элементы --- компьютер будет искать в памяти небольшие куски для хранения
        карточек. Важно, что сами карточки могут располагаться не ленте памяти 
        далеко друг от друга.
\end{itemize}

Нам важно посмотреть на то, как быстро выполняются основные операции, которые
могут понадобиться для работы со структурами данных: доступ, поиск, удаление
и вставка. Разберем их по порядку.

\begin{enumerate}
    \item Нам необходимо получить значение $i$-го элемента. В массиве это
        делается моментально --- мы просто добавляем $i$ к адресу начала
        массива и смотрим на значение в новой ячейке. В списке все хуже
        --- у нас данные связаны только указателями друг на друга.
        В этом случае нам необходимо по стрелочкам пройти до $i$-го
        элемента за $i$ шагов. 
    \item Поиск элемента по значению. Здесь наблюдается равенство: в обоих
        случаях нет ничего лучше, кроме как перебирать все элементы, пока
        не встретится нужный.
    \item Удаление элемента. В случае массива удаление с конца ничего не
        испортит и пройдет быстро. Однако, если мы захотим удалить элемент
        из середины, появится дырка. Единственный выход --- сдвинуть
        хвост массива на одну ячейку влево, чтобы не нарушить порядок
        элемента. На это уйдет число операций, равное числу элементов в
        хвосте. А вот со списком обстоят дела куда лучше --- если мы
        удаляем элемент из любого места, нам достаточно связать указателями
        соседние элементы, поэтому хватит фиксированного числа операций.
    \item Вставка элемента по выполняемым действиям похожа на удаление.
        В массиве нам ничего не остается, кроме как подвинуть хвост на
        одну ячейку вправо, чтобы освободить место для нового элемента.
        Более того, даже если мы добавляем элемент в конец, у нас может
        возникнуть ситуация, когда выделенная нам память закончится ---
        следующие ячейки заняты другими программами. Тогда компьютеру
        придется искать новый, больший по длине, свободный кусок памяти
        и копировать туда весь массив. Со списком все снова просто --- мы
        добавляем карточку и связываем ее с двумя связанными карточками
        (конечно, связи между ними надо убрать).
\end{enumerate}

Таким образом, получаем следующие результаты:
\begin{center}
    \begin{tabular}{c||c|c|c|c}
            & доступ & поиск & удаление & вставка \\
         \hline \hline
        Массив & $O(1)$ & $O(n)$ & $O(n)$ & $O(n)$ \\
        \hline
        Список & $O(n)$ & $O(n)$ & $O(1)$ & $O(1)$
    \end{tabular}
\end{center}

Мы видим, что во многом список лучше массива, хотя и далеко не всегда.
Это две базовые структуры, которые часто используются как в алгоритмах,
так и в других, более сложных структурах данных.

Одни из простых, но полезных структур данных --- стек и очередь. Разберемся,
как они устроены.

\begin{itemize}
    \item Стек. Представьте, что вы складываете тарелки друг на друга.
        Тогда, чтобы взять тарелку из середины, вам придется по одной
        брать тарелки сверху (вы очень аккуратны и не хотите разбить
        хрупкий фарфор), пока вы не доберетесь до нужной. На самом деле
        этот пример очень хорошо демонстрирует суть стека. Это структура
        данных, предназначенная для хранения множества элементов со следующим
        свойством: добавлять в множество можно любой элемент, а доступ
        есть только к последнему добавленному элементу. Также этот элемент
        можно удалить из множества. Нетрудно понять, как эффективно реализовать
        стек с помощью рассмотренного двусвязного списка.
    \item Очередь. Само название структуры данных говорит за себя.
        Это такое множество, в которое можно добавлять элементы, а
        доступ есть только к тому элементу множества, который был добавлен
        раньше других (сравните с живой очередью в магазине). Очередь,
        как и стек, достаточно просто реализуется с помощью списка.
\end{itemize}

В различных задачах данные структуры данных могут быть полезны в зависимости
от ситуации. Заметим, что мы явно не указали, как должны быть устроены стек и
очередь (только предложили эффективный способ --- с помощью списка). Нам
важно то, как эти структуры выглядят снаружи и что с ними можно делать.

\subsection{Представление графов}

Следующий этап подготовки к изучению алгоритмов на графах --- понять, как
записать граф в программе. Здесь наиболее широко используются два подхода:
матрица смежности и список смежности. Мы рассмотрим их на примере графа
авиарейсов, который мы разбирали ранее. В общем случае считаем, что имеется
неориентированный граф на $n$ вершинах без петель и кратных ребер.

Матрица смежности --- это двумерный массив размера $n \times n$, где на
позиции $[i, j]$ стоит 1, если вершины $i$ и $j$ соединены ребром и 0
иначе.

\begin{center}
    \begin{tabular}{c||c|c|c|c|c}
            & A & B & C & D & E \\
            \hline \hline
        A & 0 & 1 & 1 & 0 & 1 \\ \hline
        B & 1 & 0 & 0 & 1 & 0 \\ \hline
        C & 1 & 0 & 0 & 1 & 1 \\ \hline
        D & 0 & 1 & 1 & 0 & 0 \\ \hline
        E & 1 & 0 & 1 & 0 & 0
    \end{tabular}
    \captionof{table}{Матрица смежности графа авиарейсов}
\end{center}

Нетрудно понять, что матрица смежности всегда симметрична, то есть элемент
$[i, j]$ равен элементу $[j, i]$. Также ясно, как обобщить матрицу
смежности на более сложные графы. Для ориентированных графов элементы
$[i, j]$ и $[j, i]$ отличаются знаком. Можно задать не только само ребро,
но и его длину (например, длина дороги между городами): вместо 1 писать
нужное число. 

Список смежности --- это массив, $i$-й элемент которого является списком,
состоящим из соседей $i$-й вершины. Таким образом, в массиве записаны
указатели на первые элементы списков. Можно также хранить не список, а
массив из смежных вершин, но у этого подхода есть определенные минусы.

\begin{center}
    \begin{tabular}{c||c|c|c|c|c}
        Вершина & A & B & C & D & E \\ \hline
        Список смежности & $\{B, C, E\}$ & $\{A, D\}$ & $\{A, D, E\}$ & 
        $\{B, C\}$ & $\{A, C\}$
    \end{tabular}
    \captionof{table}{Список смежности графа авиарейсов}
\end{center}

Список смежности модифицировать не сильно сложнее: в списках придется хранить
карточки, на которых помимо указателя написана нужная информация: длина ребра.
А для ориентированного графа ребро добавляется в список только для одной
вершины (из которой выходит).

Какие есть преимущества у каждого из способов? Матрица смежности позволяет
быстро узнать, соединены ли две конкретные вершины ребром (быстрый доступ
к элементу массива). В списке смежности на это понадобится $O(n + m)$
времени, где $m$ --- число ребер в графе. Однако, список смежности позволяет
быстро определить степень вершины, а в матрице приходится перебирать весь
массив и искать сумму его элементов, что дает время $O(n)$. Есть и другие
различия по времени, но главным отличием является занимаемая память. При
использовании списка смежности достаточно хранить $O(n + m)$ чисел,
а вот матрица смежности всегда занимает $O(n^2)$ памяти. Заметим, что
в очень больших разреженных графах (например, похожих на граф интернета), то
есть с небольшим количеством ребер, разница колоссальна --- $n^2$ становится
слишком большим числом и такой граф не влезет в память ни одного компьютера.

